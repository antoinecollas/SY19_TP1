---
title: "TP3"
output:
  pdf_document: default
  html_notebook: default
---

#Problème de classification
##Chargement des données
Nous commençons par charger les données du problème de classification. Ce problème de classification ne possède que 2 classes. 43% des données appratiennent à la classe 1. 57% appartiennent à la classe 2.

```{r}
data <- read.table('../tp3_a18_clas_app.txt')
nrow(data)
sum(data[,-1]==1) / nrow(data)
sum(data[,-1]==2) / nrow(data)
```


Ensuite nous découpons l'ensemble des données en 2 ensembles: un pour l'entrainement et un pour le test.  Nous répartissons les données entre les 2 ensembles de manière aléatoire afin que nos 2 ensembles aient les mêmes proportions des étiquettes que dans l'ensemble initial. Nous fixons le générateur de nombres aléatoires afin de conserver le même ensemble de test au cours des différentes executions de ce notebook.

```{r}
set.seed(123)
ratio_training <- 3/4
train <- sample(1:nrow(data), floor(nrow(data)*ratio_training))
data_train <- data[train,]
data_test <- data[-train,]
```

##Méthode d'évaluation
Nous évaluons chaque modèle sur l'ensemble d'entrainement à l'aide d'une validation croisée (avec 10 parties). Nous calculons l'erreur moyenne et l'écart type. Nous appliquons la "One-standard-error rule" pour choisir notre modèle final. Enfin, nous estimons l'erreur de notre modèle sur l'ensemble de test. L'erreur de classification est définie par la probabilité d’erreur.

##Analyse discriminante (linéaire, quadratique et classifieur bayésien naïf).
Nous implémentons deux fonctions qui calculent l'erreur de classification et l'écart type par validation croisée pour les analyses linéaire, quadratique et le classifieur bayésien naïf.
```{r}
#fonction réalisant la validation croisée avec K=10 (pour api similaire à lda)
CV_eval <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  mean <- 0
  errors <- rep(0, K)
  for(k in (1:K)){
    model.fit <- model(formula=as.factor(y)~., data=data[folds!=k,])
    pred <- predict(model.fit, data[folds==k,])
    errors[k] <- sum(data$y[folds==k]!=pred$class) / length(pred$class)
    mean <- mean + (errors[k]*length(pred$class))
  }
  mean <- mean/n
  sd <- sqrt((1/(K-1))*sum((errors - rep(mean, K))^2))
  return(c(mean, sd))
}
```

```{r}
#fonction réalisant 10 évaluations croisées avec K=10 (pour naiveBayes)
CV_eval_naiveBayes <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  mean <- 0
  errors <- rep(0, K)
  for(k in (1:K)){
    model.fit <- model(formula=as.factor(y)~., data=data[folds!=k,])
    pred <- predict(model.fit, data[folds==k,])
    errors[k] <- sum(data$y[folds==k]!=pred) / length(pred)
    mean <- mean + (errors[k]*length(pred))
  }
  mean <- mean/n
  sd <- sqrt((1/(K-1))*sum((errors - rep(mean, K))^2))
  return(c(mean, sd))
}
```

```{r}
require(MASS)
#validation croisée sur l'ensemble d'entrainement
res <- data.frame("Erreur"=rep(0,3), "Ecart type"=rep(0,3))
row.names(res) <- c("ADL", "ADQ", "Bayésien naif")
res[1,] <- CV_eval(lda, data_train)
res[2,] <- CV_eval(qda, data_train)
library(e1071)
res[3,] <- CV_eval_naiveBayes(naiveBayes, data_train)
```
Nous obtenons les erreurs suivantes:

```{r, echo=FALSE}
knitr::kable(res)
```

## Analyse discriminante régularisée
```{r}
#essayer Regularized discriminant analysis
```

## Régression logistique

```{r}
#Régression logistique
```

```{r}
#fonction réalisant 10 évaluations croisées avec K=10 (pour régression logistique)
CV_eval_glm <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  CV <- 0
  for(k in (1:K)){
    glm.fit <- glm(y~., data=data[folds!=k,], family=binomial)
    pred <- predict(glm.fit, newdata=data[folds==k,], type='response')>0.5
    CV <- CV+sum(data$y[folds==k]!=pred)
  }
  CV <- CV/n
  return(CV)
}
```

```{r}
#validation croisée sur l'ensemble d'entrainement avec une régression logistique
data_train_glm <- data_train
data_train_glm$y <- data_train_glm$y - 1
CV_eval_glm(glm, data_train_glm)  # 30% d'erreur
```


```{r}
#ROC
```


```{r}
#ROC
```