---
title: "TP3"
output:
  pdf_document: default
  html_notebook: default
---

#Problème de classification
##Chargement des données
Nous commençons par charger les données du problème de classification. Ce problème de classification ne possède que 2 classes. 43% des individus appratiennent à la classe 1. 57% appartiennent à la classe 2. Ce jeu de données contient 200 individus, chacun est décrit par 36 variables.

```{r}
full_data <- read.table('../tp3_a18_clas_app.txt')
nrow(full_data)
sum(full_data[,-1]==1) / nrow(full_data)
sum(full_data[,-1]==2) / nrow(full_data)
```


Ensuite nous découpons l'ensemble des données en 2 ensembles: un pour l'entrainement et un pour le test.  Nous répartissons les données entre les 2 ensembles de manière aléatoire afin que nos 2 ensembles aient les mêmes proportions des étiquettes que dans l'ensemble initial. Nous fixons le générateur de nombres aléatoires afin de conserver le même ensemble de test au cours des différentes executions de ce notebook.

```{r}
set.seed(123)
ratio_training <- 3/4
train <- sample(1:nrow(full_data), floor(nrow(full_data)*ratio_training))
data_train <- full_data[train,]
data_test <- full_data[-train,]
```

##Méthode d'évaluation
Nous évaluons chaque modèle sur l'ensemble d'entrainement à l'aide d'une validation croisée (avec 10 parties). Nous calculons l'erreur moyenne et l'écart type. Nous appliquons la "One-standard-error rule" pour choisir notre modèle final. Enfin, nous estimons l'erreur de notre modèle sur l'ensemble de test. L'erreur de classification est définie par la probabilité d’erreur.

##Analyse discriminante (linéaire, quadratique et classifieur bayésien naïf).
Nous implémentons deux fonctions qui calculent l'erreur de classification et l'écart type par validation croisée pour les analyses linéaire, quadratique et le classifieur bayésien naïf.
```{r}
#fonction réalisant la validation croisée avec K=10 (pour api similaire à lda)
CV_eval <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  mean <- 0
  errors <- rep(0, K)
  for(k in (1:K)){
    model.fit <- model(formula=as.factor(y)~., data=data[folds!=k,])
    pred <- predict(model.fit, data[folds==k,])
    errors[k] <- sum(data$y[folds==k]!=pred$class) / length(pred$class)
    mean <- mean + (errors[k]*length(pred$class))
  }
  mean <- mean/n
  sd <- sqrt((1/(K-1))*sum((errors - rep(mean, K))^2))
  return(c(mean, sd))
}
```

```{r}
#fonction réalisant 10 évaluations croisées avec K=10 (pour naiveBayes)
CV_eval_naiveBayes <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  mean <- 0
  errors <- rep(0, K)
  for(k in (1:K)){
    model.fit <- model(formula=as.factor(y)~., data=data[folds!=k,])
    pred <- predict(model.fit, data[folds==k,])
    errors[k] <- sum(data$y[folds==k]!=pred) / length(pred)
    mean <- mean + (errors[k]*length(pred))
  }
  mean <- mean/n
  sd <- sqrt((1/(K-1))*sum((errors - rep(mean, K))^2))
  return(c(mean, sd))
}
```

```{r}
require(MASS)
set.seed(123)
#validation croisée sur l'ensemble d'entrainement
res <- data.frame("Erreur"=rep(0,3), "Ecart type"=rep(0,3))
row.names(res) <- c("ADL", "ADQ", "Bayésien naif")
res[1,] <- CV_eval(lda, data_train)
res[2,] <- CV_eval(qda, data_train)
library(e1071)
res[3,] <- CV_eval_naiveBayes(naiveBayes, data_train)
```
Nous obtenons les erreurs suivantes:

```{r, echo=FALSE}
knitr::kable(res)
```

## Analyse discriminante régularisée
Dans cette partie nous utilisons une analyse discriminante régularisée implémentée dans le package **klaR**. Cette implémentation permet d'obtenir des modèles régularisés de l'analyse disciminante linéaire, de l'analyse discriminante quadratique et du classifieur bayésien naïf. L'impléméntation cherche les hyperparamètres $\gamma$ et $\lambda$ à l'aide d'une validation croisée sur l'ensemble d'entrainement. Les hyperparamètres optimaux trouvés sont $\gamma=0.86$ et $\lambda=0.04$. D'après la [documentation du package klaR](https://cran.r-project.org/web/packages/klaR/klaR.pdf) (page 58), cela correspond à des matrices de variances-covariances dont les termes de chaque diagonale sont quasiement égaux et les éléments en dehors de la diagonale sont proches de 0. Ce classifieur correspond à un classifieur bayésien naïf régularisé (par les termes des diagonales de matrices de variances-covariances égaux). L'erreur trouvée est proche de celle trouvée du classifieur bayésien naïf.

```{r}
require(klaR)
set.seed(123)
model <- rda(formula=as.factor(y)~., data=data_train, crossval=TRUE, fold=10)
model$regularization
model$error.rate[2]
```

## Régression logistique
Nous testons la régression logistique bien que ce modèle soit similaire à l'analyse discriminante linéaire (qui ne diffère que par l'évaluation des poids).
```{r}
#fonction réalisant 10 évaluations croisées avec K=10 (pour régression logistique)
CV_eval_glm <- function(model, data){
  K <- 10
  n <- nrow(data)
  folds <- sample(1:K,n,replace=TRUE)
  mean <- 0
  errors <- rep(0, K)
  for(k in (1:K)){
    glm.fit <- glm(as.factor(y)~., data=data[folds!=k,], family=binomial)
    pred <- predict(glm.fit, newdata=data[folds==k,], type='response')>0.5
    errors[k] <- sum(data$y[folds==k]!=pred) / length(pred)
    mean <- mean + (errors[k]*length(pred))
  }
  mean <- mean/n
  sd <- sqrt((1/(K-1))*sum((errors - rep(mean, K))^2))
  return(c(mean, sd))
}
```

```{r}
set.seed(123)
#validation croisée sur l'ensemble d'entrainement avec une régression logistique
data_train_glm <- data_train
data_train_glm$y <- data_train_glm$y - 1
res <- data.frame("Erreur"=0, "Ecart type"=0)
row.names(res) <- "Regression logistique"
res[1,] <- suppressWarnings(CV_eval_glm(glm, data_train_glm))
```
Comme attendu, nous obtenons une erreur très proche de ADL:
```{r, echo=FALSE}
knitr::kable(res)
```
```{r}
#Extraction des prédicteurs intéressants (Factor discriminant analysis, PCA, corrélations, corrélations fournies pas la régression logistique, ...)
```

```{r}
#ROC des différents modèles
#matrice de confusion du meilleur modèle
```

# Problème de régression
## Chargement des données
Nous commençons par charger les données du problème de régression. Ce problème contient 200 individus (comme le problème de classification). Chaque individu est decrit par 50 variables quantitatives. La variable nommée "y" est la variable à prédire.

```{r}
rm(list=ls())
full_data <- read.table('../tp3_a18_reg_app.txt')
nrow(full_data)
```


Ensuite nous découpons l'ensemble des données en 2 ensembles: un pour l'entrainement et un pour le test. Nous fixons le générateur de nombres aléatoires afin de conserver le même ensemble de test au cours des différentes executions de ce notebook.

```{r}
set.seed(123)
ratio_training <- 3/4
train <- sample(1:nrow(full_data), floor(nrow(full_data)*ratio_training))
data_train <- full_data[train,]
data_test <- full_data[-train,]
```

## Méthode d'évaluation
Pour ce problème l'erreur de régression est définie par l'espérance de l'erreur quadratique. Nous estimons cette erreur et son écart type pour chaque modèle sur l'ensemble d'entrainement à l'aide d'une validation croisée (avec 10 parties). Ensuite, nous appliquons la "One-standard-error rule" pour choisir notre modèle final. Enfin, nous estimons l'erreur de notre modèle sur l'ensemble de test. 

## Régression linéaire
Nous commençons par appliquer une régression linéaire sur toutes les variables.
```{r}
reg <- lm(formula = y~., data=data_train)
```
